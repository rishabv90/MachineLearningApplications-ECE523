{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Risahb Verma 4/7/2020\n",
    "#Adaboost implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://github.com/jaimeps/adaboost-implementation/blob/master/adaboost.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix\n",
    "def sample(p):\n",
    "    X = np.random.uniform(low=0.0, high=1.0, size=100) #uniform random numbers\n",
    "    M = []\n",
    "    for i in np.nditer(X):\n",
    "       if(i <= 0.7):\n",
    "           M.append(0)\n",
    "       elif(i >0.7 and i <=0.9):#0.9 is cdf as p[0]+p[1]\n",
    "        M.append(1)\n",
    "       elif(i > 0.9 and i <= 1):#0.9 is cdf as p[0]+p[1]+p[2]\n",
    "        M.append(2)\n",
    "    \n",
    "    return M \n",
    "\n",
    "n = np.array([1,2,3])\n",
    "p = np.array([.7, .2, .1])\n",
    "M = sample(p)\n",
    "\n",
    "count0 = 0\n",
    "count1 = 0\n",
    "count2 = 0\n",
    "for i in M: \n",
    "    if i ==0: count0 +=1\n",
    "    elif i ==1:count1 +=1\n",
    "    elif i==2:count2 +=1\n",
    "    \n",
    "#print(count0/100,count1/100, count2/100)  \n",
    "\n",
    "#Sampling from Homework #1\n",
    "def randomGenerate(d):\n",
    "    s = 0\n",
    "    randnum = random.randint(1, 100)\n",
    "    for index, scope in enumerate(d):\n",
    "        s += scope\n",
    "        if randnum <= s:\n",
    "            break\n",
    "    return index\n",
    "\n",
    "def sample2(samples , d):\n",
    "    if samples <= 0:\n",
    "        return [-1]\n",
    "    l = []\n",
    "    for item in range(0,samples):\n",
    "        l.append(randomGenerate(d))\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt('blood_train.csv', delimiter = ',')\n",
    "testData = np.loadtxt('blood_test.csv', delimiter = ',')\n",
    "X = data[:, 0:-1]\n",
    "y = data[:, -1]\n",
    "X_test = testData[:, 0:-1]\n",
    "y_test = testData[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ada():\n",
    "    def __init__(self, rounds=15, weak_classifier = []):\n",
    "        self.rounds=rounds\n",
    "        self.H = []\n",
    "        self.alpha = []\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        number_N, numbers_Xs = np.shape(X)  \n",
    "         # Step 1: Intialize equal weight to 1/N to each sample of train_data data points as    \n",
    "        P_d = (np.ones((number_N))) / number_N\n",
    "        np.shape(P_d)\n",
    "        weak_classifier = DecisionTreeClassifier(max_depth=2)\n",
    "        y = np.transpose(y)\n",
    "        # Step 2: Learning Classifier\n",
    "        for t in range (self.rounds):\n",
    "            X_s, y_s = sampling(P_d, number_N, X_train, y_train)\n",
    "            weak_classifier.fit(X_s, y_s)\n",
    "            y_pred = weak_classifier.predict(X_s)\n",
    "            error_h = np.sum(np.abs(np.subtract(y_train,y_pred))) / len(y_train)\n",
    "    \n",
    "            # Step 3: epsilon_t - Weighted error\n",
    "            dist_size = len(P_d)\n",
    "            vec = np.abs(np.subtract(y, y_pred))\n",
    "            eps_error = 0.0\n",
    "            for i in range (dist_size):\n",
    "                total_eps_error = eps_error + (P_d[i]*vec[i])\n",
    "            #print('Total Epsilon Error', total_eps_error)\n",
    "\n",
    "            # Step 4: finding Alpha_t\n",
    "            alpha_t = 0.5 * math.log10((1-total_eps_error)/ total_eps_error)\n",
    "            self.alpha.append(alpha_t) \n",
    "\n",
    "            # Step 5: New Weighted, Normalized\n",
    "            new_P_distr = new_Prob_Dist(P_d, total_eps_error, alpha_t, y, y_pred)\n",
    "\n",
    "            # Step 6,7: Output H(x)\n",
    "            self.H.append(weak_classifier)\n",
    "        \n",
    "    \"\"\"Function for predicting\"\"\"\n",
    "    def predict(self,X):\n",
    "        n_sample, n_feature = np.shape(X)\n",
    "        y_pred = np.zeros((n_sample))\n",
    "        for clf, alph in zip(self.H,self.alpha):\n",
    "            y_temp = clf.predict(X)\n",
    "            y_pred = y_pred + (alph * y_temp)\n",
    "        \n",
    "        y_pred = threshold(y_pred)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.4197  ,  1.2819  ,  1.2819  ,  0.93195 ],\n",
       "       [ 0.060938, -0.088145, -0.088145,  0.15252 ],\n",
       "       [-0.92728 ,  0.25436 ,  0.25436 ,  0.029451],\n",
       "       [-0.30964 ,  1.1106  ,  1.1106  ,  2.1216  ],\n",
       "       [-0.92728 , -0.088145, -0.088145,  0.52172 ],\n",
       "       [ 0.18446 , -0.088145, -0.088145,  0.15252 ],\n",
       "       [-0.68022 ,  0.083108,  0.083108, -0.17566 ],\n",
       "       [ 0.55505 , -0.43065 , -0.43065 ,  1.8344  ],\n",
       "       [ 0.55505 , -0.43065 , -0.43065 ,  1.8344  ],\n",
       "       [ 1.6668  , -0.77316 , -0.77316 , -0.46282 ],\n",
       "       [-1.0508  ,  3.1657  ,  3.1657  ,  1.7524  ],\n",
       "       [-0.92728 , -0.2594  , -0.2594  , -0.74998 ],\n",
       "       [ 0.8021  , -0.77316 , -0.77316 , -0.74998 ],\n",
       "       [-0.68022 ,  0.93937 ,  0.93937 ,  1.7934  ],\n",
       "       [ 0.55505 , -0.2594  , -0.2594  , -0.25771 ],\n",
       "       [ 1.4197  , -0.77316 , -0.77316 , -0.54487 ],\n",
       "       [-0.30964 , -0.60191 , -0.60191 , -0.74998 ],\n",
       "       [-0.80375 , -0.2594  , -0.2594  , -0.21669 ],\n",
       "       [ 1.6668  , -0.43065 , -0.43065 ,  0.029451],\n",
       "       [ 0.8021  ,  0.083108,  0.083108,  1.9165  ],\n",
       "       [ 0.18446 ,  0.25436 ,  0.25436 ,  1.1371  ],\n",
       "       [-0.80375 , -0.2594  , -0.2594  , -0.21669 ],\n",
       "       [ 0.18446 , -0.088145, -0.088145,  0.15252 ],\n",
       "       [-0.68022 ,  0.59687 ,  0.59687 ,  0.15252 ],\n",
       "       [ 0.55505 ,  0.25436 ,  0.25436 ,  0.029451],\n",
       "       [-0.68022 , -0.088145, -0.088145,  0.97297 ],\n",
       "       [ 1.4197  , -0.60191 , -0.60191 , -0.46282 ],\n",
       "       [ 0.18446 , -0.43065 , -0.43065 , -0.33975 ],\n",
       "       [-0.92728 , -0.2594  , -0.2594  , -0.74998 ],\n",
       "       [-0.92728 , -0.60191 , -0.60191 , -0.46282 ],\n",
       "       [-0.68022 ,  1.7956  ,  1.7956  ,  1.4652  ],\n",
       "       [ 1.6668  , -0.60191 , -0.60191 , -0.46282 ],\n",
       "       [ 1.6668  , -0.77316 , -0.77316 , -0.46282 ],\n",
       "       [ 0.55505 ,  0.25436 ,  0.25436 ,  0.029451],\n",
       "       [-0.92728 , -0.2594  , -0.2594  , -0.74998 ],\n",
       "       [ 0.060938,  0.42562 ,  0.42562 ,  0.19354 ],\n",
       "       [ 0.8021  ,  0.25436 ,  0.25436 ,  2.1626  ],\n",
       "       [-0.68022 ,  0.76812 ,  0.76812 , -0.25771 ],\n",
       "       [-0.68022 ,  0.42562 ,  0.42562 ,  0.23456 ],\n",
       "       [-0.68022 , -0.77316 , -0.77316 , -1.2423  ],\n",
       "       [ 1.4197  , -0.77316 , -0.77316 , -0.54487 ],\n",
       "       [ 0.55505 , -0.77316 , -0.77316 , -0.83203 ],\n",
       "       [ 0.18446 ,  0.59687 ,  0.59687 , -0.052595],\n",
       "       [-0.92728 , -0.2594  , -0.2594  , -0.74998 ],\n",
       "       [-0.80375 , -0.2594  , -0.2594  , -0.21669 ],\n",
       "       [-0.68022 , -0.77316 , -0.77316 , -1.2423  ],\n",
       "       [ 0.8021  ,  1.1106  ,  1.1106  ,  0.64479 ],\n",
       "       [ 0.8021  , -0.43065 , -0.43065 , -0.011572],\n",
       "       [ 0.18446 ,  0.25436 ,  0.25436 ,  1.1371  ],\n",
       "       [-0.68022 ,  0.93937 ,  0.93937 ,  1.096   ]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = sample2(50,[100 / X.shape[0]] * X.shape[0])\n",
    "Xtrain = []\n",
    "yTrain = []\n",
    "\n",
    "\n",
    "for i in range(0,50):\n",
    "    Xtrain = np.append(Xtrain, X[a[i]])\n",
    "    yTrain = np.append(yTrain, y[a[i]])\n",
    "\n",
    "Xtrain = Xtrain.reshape(50, 4)\n",
    "Xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "                   base_estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                                         criterion='gini',\n",
       "                                                         max_depth=1,\n",
       "                                                         max_features=None,\n",
       "                                                         max_leaf_nodes=None,\n",
       "                                                         min_impurity_decrease=0.0,\n",
       "                                                         min_impurity_split=None,\n",
       "                                                         min_samples_leaf=1,\n",
       "                                                         min_samples_split=2,\n",
       "                                                         min_weight_fraction_leaf=0.0,\n",
       "                                                         presort=False,\n",
       "                                                         random_state=None,\n",
       "                                                         splitter='best'),\n",
       "                   learning_rate=1.0, n_estimators=200, random_state=None)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=1),\n",
    "    n_estimators=200\n",
    ")\n",
    "classifier.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7333333333333333"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = classifier.predict(X_test)\n",
    "confusion_matrix(y_test, predictions)\n",
    "clf = AdaBoostClassifier(n_estimators=10, random_state=0)\n",
    "clf.fit(X, y)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
